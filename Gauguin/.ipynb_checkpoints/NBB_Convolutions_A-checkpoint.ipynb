{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathematics (and, in particular, functional analysis)\n",
    "[convolution](https://en.wikipedia.org/wiki/Convolution)  is a mathematical operation on two functions ($f$\n",
    "and $g$) to produce a third function, that is typically viewed as a\n",
    "modified version of one of the original functions, giving the integral\n",
    "of the pointwise multiplication of the two functions as a function of\n",
    "the amount that one of the original functions is translated.\n",
    "\n",
    "![convolution](http://nikbearbrown.com/YouTube/MachineLearning/IMG/Comparison_convolution_correlation.svg.png)\n",
    "\n",
    "Convolution is similar to cross-correlation. For discrete real valued\n",
    "signals, they differ only in a time reversal in one of the signals. For\n",
    "continuous signals, the cross-correlation operator is the adjoint\n",
    "operator of the convolution operator.\n",
    "\n",
    "It has applications that include probability, statistics, computer\n",
    "vision, natural language processing, image and signal processing,\n",
    "engineering, and differential equations.\n",
    "\n",
    "The convolution can be defined for functions on groups other than\n",
    "Euclidean space. For example, periodic functions, such as the\n",
    "discrete-time Fourier transform, can be defined on a circle and\n",
    "convolved by *periodic convolution*. A *discrete convolution* can be defined for functions on\n",
    "the set of integers.\n",
    "\n",
    "Generalizations of convolution have applications in the field of\n",
    "numerical analysis and numerical linear algebra, and in the design\n",
    "and implementation of finite impulse response filters in signal\n",
    "processing.\n",
    "\n",
    "Computing the inverse of the convolution operation is known as\n",
    "_deconvolution_.\n",
    "\n",
    "\n",
    "### Definition  \n",
    "\n",
    "\n",
    "The convolution of $f$ and $g$ is written $f∗g$, using an asterisk\n",
    "or star. It is defined as the integral of the product of the two\n",
    "functions after one is reversed and shifted. As such, it is a particular\n",
    "kind of integral transform:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(f * g )(t) & \\, \\stackrel{\\mathrm{def}}{=}\\ \\int_{-\\infty}^\\infty f(\\tau) g(t - \\tau) \\, d\\tau \\\\\n",
    "& = \\int_{-\\infty}^\\infty f(t-\\tau) g(\\tau)\\, d\\tau.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "While the symbol $t$ is used above, it need not represent the time\n",
    "domain. But in that context, the convolution formula can be described as\n",
    "a weighted average of the function $f*(\\tau)$ at the moment $t$ where the\n",
    "weighting is given by $g(−\\tau)$ simply shifted by amount $t$. As $t$\n",
    "changes, the weighting function emphasizes different parts of the input\n",
    "function.\n",
    "\n",
    "For functions $f$, $g$ supported on only $0, \\infty$ (i.e., zero for\n",
    "negative arguments), the integration limits can be truncated, resulting\n",
    "in\n",
    "\n",
    "$$\n",
    "(f * g )(t) = \\int_{0}^{t} f(\\tau) g(t - \\tau)\\, d\\tau \\text{ for } f, g : 0, \\infty \\to \\mathbb{R}\n",
    "$$\n",
    "\n",
    "In this case, the Laplace transform is more appropriate than the\n",
    "Fourier transform below and boundary terms become relevant.\n",
    "\n",
    "\n",
    "\n",
    "### Visual explanation\n",
    "\n",
    "**Example A**\n",
    "\n",
    "![Visual explanation A](http://nikbearbrown.com/YouTube/MachineLearning/IMG/799px-Convolution3.svg.png)\n",
    "\n",
    "\n",
    "1.  Express each function in terms of a dummy variable $\\tau.$   \n",
    "2.  Reflect one of the functions: $g(\\tau)$→$g(-\\tau).$  \n",
    "3.  Add a time-offset, *t*, which allows $g(t-\\tau)$ to slide along the\n",
    "    $\\tau$-axis.  \n",
    "4.  Start *t* at −∞ and slide it all the way to +∞. Wherever the two\n",
    "    functions intersect, find the integral of their product. In other\n",
    "    words, compute a <u>sliding</u>, weighted-sum of function $f(\\tau)$,\n",
    "    where the weighting function is $g(-\\tau).$  \n",
    "\n",
    "**Example B**\n",
    "\n",
    "![Visual explanation B](http://nikbearbrown.com/YouTube/MachineLearning/IMG/Convolution_of_box_signal_with_itself2.gif)\n",
    "\n",
    "\n",
    "   In this example, the red-colored \\\"pulse\\\", $g(\\tau),$ is an even\n",
    "    function $(\\ g(-\\tau)=g(\\tau)\\ ),$ so convolution is equivalent to\n",
    "    correlation. A snapshot of this \\\"movie\\\" shows functions\n",
    "    $g(t-\\tau)$ and $f(\\tau)$ (in blue) for some value of parameter $t,$\n",
    "    which is arbitrarily defined as the distance from the $\\tau=0$ axis\n",
    "    to the center of the red pulse. The amount of yellow is the area of\n",
    "    the product $f(\\tau)\\cdot g(t-\\tau),$ computed by the\n",
    "    convolution/correlation integral. The movie is created by\n",
    "    continuously changing $t$ and recomputing the integral. The result\n",
    "    (shown in black) is a function of $t,$ but is plotted on the same\n",
    "    axis as $\\tau,$ for convenience and comparison.\n",
    "\n",
    "**Example C**\n",
    "\n",
    "![Visual explanation C](http://nikbearbrown.com/YouTube/MachineLearning/IMG/Convolution_of_spiky_function_with_box2.gif)\n",
    "\n",
    "\n",
    "   In this depiction, $f(\\tau)$ could represent the response of an RC\n",
    "    circuit to a narrow pulse that occurs at $\\tau=0.$ In other words,\n",
    "    if $g(\\tau)=\\delta(\\tau),$ the result of convolution is just $f(t).$\n",
    "    But when $g(\\tau)$ is the wider pulse (in red), the response is a\n",
    "    \\\"smeared\\\" version of $f(t).$ It begins at $t=-0.5,$ because we\n",
    "    defined $t$ as the distance from the $\\tau=0$ axis to the\n",
    "    <u>center</u> of the wide pulse (instead of the leading edge).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Bring in python image analysis libraries\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "import skimage.filters as filters\n",
    "from skimage.transform import hough_circle\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import feature\n",
    "from skimage import morphology\n",
    "from skimage.draw import circle_perimeter\n",
    "from skimage import img_as_float, img_as_ubyte\n",
    "from skimage import segmentation as seg\n",
    "from skimage.morphology import watershed\n",
    "from scipy import ndimage as nd\n",
    "from scipy.ndimage import convolve\n",
    "from skimage import feature\n",
    "import glob # for bulk file import\n",
    "\n",
    "# Set defaults\n",
    "plt.rcParams['image.cmap'] = 'gray' # Display grayscale images in... grayscale.\n",
    "plt.rcParams['image.interpolation'] = 'none' # Use nearest-neighbour\n",
    "plt.rcParams['figure.figsize'] = 10, 10\n",
    "\n",
    "# Import test images\n",
    "imgpaths = glob.glob(\"./images/*.jpg\") + glob.glob(\"./images/*.png\")\n",
    "# imgpaths = glob.glob(\"img/*.jpg\") + glob.glob(\"img/*.png\")  Windows\n",
    "# Windows has different relative paths than Mac/Unix\n",
    "imgset = [mpimg.imread(x) for x in imgpaths]\n",
    "\n",
    "# Display thumbnails of the images to make sure they loaded\n",
    "plt.figure()\n",
    "for i,img in enumerate(imgset):\n",
    "    plt.subplot(1, len(imgset), i+1)\n",
    "    plt.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,img in enumerate(imgset):\n",
    "    plt.figure()\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,img in enumerate(imgset):\n",
    "    img_bw = img_as_float(color.rgb2grey(img))\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1) # One row, two columns, image 1\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1, 2, 2)  # One row, two columns, image 2\n",
    "    plt.imshow(img_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Edge Detection\n",
    "\n",
    "A simple edge detection algorithm would look for edges where there is the greatest difference amongst pixels and their neighbors. Let's try it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find horizontal edges using a simple shifting method\n",
    "def find_horizontal_edges(img):\n",
    "    imgbw = img_as_float(color.rgb2grey(img))\n",
    "    return np.abs(imgbw[:, 1:] - imgbw[:, :-1])\n",
    "\n",
    "# Find vertical edges using a simple shifting method\n",
    "def find_vertical_edges(img):\n",
    "    imgbw = img_as_float(color.rgb2grey(img))\n",
    "    return np.abs(imgbw[1:, :] - imgbw[:-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to image set\n",
    "for i,img in enumerate(imgset):\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Horizontal Edges')\n",
    "    plt.imshow(find_horizontal_edges(img))\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Vertical Edges')\n",
    "    plt.imshow(find_vertical_edges(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample an image by skipping indicies\n",
    "def downsample_image(img, skip):\n",
    "     return img[::skip,::skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to image set\n",
    "for i,img in enumerate(imgset):\n",
    "    img = downsample_image(img, 11) # downsample    \n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to image set\n",
    "for i,img in enumerate(imgset):\n",
    "    img = downsample_image(img, 5) # downsample    \n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title('Horizontal Edges')\n",
    "    plt.imshow(find_horizontal_edges(img))\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title('Vertical Edges')\n",
    "    plt.imshow(find_vertical_edges(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last update October 3, 2017\n",
    "\n",
    "The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
